{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste från lab0\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        print(f\"Device: {str(self.device).upper()}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm = True):\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "    auc = roc_auc_score(all_targets, [p[1] for p in all_probs])\n",
    "        \n",
    "    print(f\"\\rAccuracy  : {accuracy*100:.2f}%\")\n",
    "    print(f\"Precision : {precision*100:.2f}%\")\n",
    "    print(f\"Recall    : {recall*100:.2f}%\")\n",
    "    print(f\"F1 Score  : {f1*100:.2f}%\")\n",
    "    print(f\"AUC Score : {auc*100:.2f}%\")\n",
    "    if display_cm:\n",
    "        cm = confusion_matrix(all_targets, all_predictions)\n",
    "        plt.figure(figsize=(4,4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Truth')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(nn, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate = False) -> None:\n",
    "    \"\"\"\n",
    "    Train and validate a neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    - nn : torch.nn.Module\n",
    "        The neural network model to train and validate.\n",
    "    - train_loader : DataLoader\n",
    "        The DataLoader containing the training dataset.\n",
    "    - val_loader : DataLoader\n",
    "        The DataLoader containing the validation dataset.\n",
    "    - criterion : torch.nn.Module\n",
    "        The loss function to use.\n",
    "    - optimizer : torch.optim.Optimizer\n",
    "        The optimizer to use.\n",
    "    - num_epochs : int\n",
    "        The number of epochs to train the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    nn.to(nn.device)\n",
    "    \n",
    "    n = int(len(str(abs(num_epochs))))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        nn.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        ind = 0\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = nn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            print(f\"\\rTraining.. Epoch [{epoch+1:>n}/{num_epochs:>n}], ({ind+1:>3}/{len(train_loader)})\", end = \"\")\n",
    "            ind += 1\n",
    "\n",
    "        nn.eval()\n",
    "        total_val_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ind = 0\n",
    "            for batch in val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "\n",
    "                outputs = nn(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_predictions += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                print(f\"\\rValidating Epoch [{epoch+1:>n}/{num_epochs:>n}], ({ind+1:>3}/{len(val_loader):>3})\", end = \"\")\n",
    "                ind += 1\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        print(f'\\r.......... Epoch [{epoch+1:>n}/{num_epochs:>n}], ({len(val_loader):>3}/{len(val_loader):>3}), Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy*100:.2f}%', end = \"\")\n",
    "        if print_seperate:\n",
    "            print()\n",
    "    print()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def test_model(nn, test_loader, display_cm = True) -> None:\n",
    "    \"\"\"\n",
    "    Test a neural network model on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model : torch.nn.Module\n",
    "        The trained neural network model to test.\n",
    "    - test_loader : DataLoader\n",
    "        The DataLoader for the test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(\"\\rTesting...\", end = \"\")\n",
    "    nn.to(nn.device)\n",
    "    nn.eval()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "            outputs = nn(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # För F1, Rec, Pre, AUC:\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Compute evalulation metrics\n",
    "    evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_prediction(models: list[torch.nn.Module], inputs: torch.Tensor):\n",
    "    device = models[0].device\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "    # Averagar modellernas output, vi borde testa typ weighted averaging och eller boosting\n",
    "    with torch.no_grad():\n",
    "        outputs = sum(model(inputs) for model in models) / len(models)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "def test_ensemble(models: list[torch.nn.Module], test_loader: DataLoader, display_cm = True):\n",
    "    device = models[0].device\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = ensemble_prediction(models, inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # För F1, Rec, Pre, AUC:\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_directory = \"C:/Users/hampu/Documents/kurser/år3/d7047e/images\"\n",
    "local_directory = \"C:/Users/hampek/Documents/school/d7047e/images\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4815], std=[0.2221]) # <-- beräknat med compute_mean_std() mean=[0.4815], std=[0.2221]\n",
    "])\n",
    "\n",
    "full_dataset = ImageFolder(root=local_directory, transform=transform)\n",
    "\n",
    "# 70/15/15 split\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True,  num_workers = num_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size = batch_size, shuffle=False, num_workers = num_workers)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size = batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(): \n",
    "    # tar fram mean och std för hela datasettet, till transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    data = ImageFolder(root=local_directory, transform=transform)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False)\n",
    "\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    total_samples = 0\n",
    "    for data, _ in loader:\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        total_samples += batch_samples\n",
    "\n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "\n",
    "    print(\"Mean:\", mean)\n",
    "    print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n",
      ".......... Epoch [1/1], ( 28/ 28), Train Loss: 0.3083, Val Loss: 0.1475, Accuracy: 93.96%\n",
      "\n",
      "Accuracy  : 95.56%\n",
      "Precision : 95.54%\n",
      "Recall    : 95.56%\n",
      "F1 Score  : 95.52%\n",
      "AUC Score : 97.52%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFzCAYAAAAwr8JYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtU0lEQVR4nO3de1wU9f4/8NdyW7ntIiq7oKKUqVDkBQ23vKSSqOQlsdLQsEyPBqYgafxSMzTXrI7JSaX8qtDFLCvNyEuEiqaISgczNVLT0HBBJSBIlsvO7w8f7jl7RGV3YRdmXs8e83jIzGdmPqv29r3vec+MTBAEAUREJFoO9p4AERE1LQZ6IiKRY6AnIhI5BnoiIpFjoCciEjkGeiIikWOgJyISOQZ6IiKRY6AnIhI5J3tPoCks7hRl7ymQDb1Z/IO9p0A2dP3671btX3P1N4v3dW57j1XnthdRBnoiotsy1Nl7BjbHQE9E0iIY7D0Dm2OgJyJpMUgv0PNiLBGRyDGjJyJJEVi6ISISOQmWbhjoiUhamNETEYkc2yuJiEROghk9u26IiJrIH3/8gUmTJqFNmzZwdXVFcHAwjh07ZtwuCAIWLVoEX19fuLq6IiwsDGfOnDE5RklJCaKioqBQKODl5YWpU6eioqLCrHkw0BORtBgMli9m+PPPP/HII4/A2dkZO3fuxKlTp/DOO++gdevWxjErVqxAcnIyUlJSkJOTA3d3d4SHh6Oqqso4JioqCidPnkRGRgbS09Oxf/9+TJ8+3ay5yARBEMzaowXgs26khc+6kRZrn3WjP3fY4n3l9/Zr8NhXXnkFBw8exIEDB+rdLggC/Pz8MHfuXCQkJAAAysrKoFKpkJqaigkTJuD06dMICgrC0aNH0adPHwDArl27MHLkSFy6dAl+fn4NmgszeiKSFisyer1ej/LycpNFr9fXe5rt27ejT58+ePLJJ+Hj44NevXph3bp1xu3nz5+HTqdDWFiYcZ1SqURoaCiys7MBANnZ2fDy8jIGeQAICwuDg4MDcnJyGvyRGeiJSFoEg8WLVquFUqk0WbRabb2n+e2337B27Vrcd9992L17N2bOnImXXnoJaWlpAACdTgcAUKlUJvupVCrjNp1OBx8fH5PtTk5O8Pb2No5pCHbdEJG0WNFemZiYiPj4eJN1crm8/tMYDOjTpw+WLVsGAOjVqxd+/vlnpKSkIDo62uI5WIIZPRFRA8nlcigUCpPldoHe19cXQUFBJusCAwNRUFAAAFCr1QCAoqIikzFFRUXGbWq1GsXFxSbba2trUVJSYhzTEAz0RCQtVpRuzPHII48gPz/fZN2vv/6KTp06AQACAgKgVquRmZlp3F5eXo6cnBxoNBoAgEajQWlpKXJzc41j9uzZA4PBgNDQ0AbPhaUbIpIWGz3rJi4uDg8//DCWLVuGp556CkeOHMEHH3yADz74AAAgk8kwZ84cLF26FPfddx8CAgKwcOFC+Pn5YezYsQBufAMYPnw4pk2bhpSUFNTU1CA2NhYTJkxocMcNwEBPRFJjoztj+/bti61btyIxMRFJSUkICAjAu+++i6io/7R/z5s3D5WVlZg+fTpKS0vRv39/7Nq1C61atTKO+eSTTxAbG4uhQ4fCwcEBkZGRSE5ONmsu7KOnFo999NJidR/9T7st3lf+YLhV57YXZvREJCmCIL2HmvFiLBGRyDGjJyJpkeDTKxnoiUha+IYpIiKRY0ZPRCRyfMMUEZHISTCjZ9cNEZHIMaMnImnhxVgiIpGTYOmGgZ6IpIUZPRGRyDHQExGJG591Q0REosOMnoikhaUbIiKRY9cNEZHIMaMnIhI5ZvRERCInwYyeXTdERCLHjJ6IpIWlGyIikZNg6YaBnoikhYGeiEjkWLohIhI5CWb07LohIhI5ZvREJC0s3RARiZwESzcM9EQkLczoiYhEjhk9EZHISTDQs+uGiEjkmNETkbQIgr1nYHMM9EQkLRIs3TDQE5G0MNATEYkc2yuJiEROghk9u26IiESOGT0RSYsEu26Y0RORtBgMli9mWLx4MWQymcnSvXt34/aqqirExMSgTZs28PDwQGRkJIqKikyOUVBQgIiICLi5ucHHxwcvv/wyamtrzf7IzOiJSFpsWKO///778f333xt/dnL6T8iNi4vDt99+iy1btkCpVCI2Nhbjxo3DwYMHAQB1dXWIiIiAWq3GoUOHcPnyZTz77LNwdnbGsmXLzJoHAz0RSYsNu26cnJygVqtvWV9WVob169dj06ZNGDJkCABg48aNCAwMxOHDh9GvXz989913OHXqFL7//nuoVCr07NkTS5Yswfz587F48WK4uLg0eB4s3RCRpAgGweJFr9ejvLzcZNHr9bc915kzZ+Dn54d77rkHUVFRKCgoAADk5uaipqYGYWFhxrHdu3eHv78/srOzAQDZ2dkIDg6GSqUyjgkPD0d5eTlOnjxp1mdmoCciaiCtVgulUmmyaLXaeseGhoYiNTUVu3btwtq1a3H+/HkMGDAAf/31F3Q6HVxcXODl5WWyj0qlgk6nAwDodDqTIH9z+81t5mDphoikxYoafWJiIuLj403WyeXyeseOGDHC+OsHH3wQoaGh6NSpEz7//HO4urpaPAdLMKMnImkRDBYvcrkcCoXCZLldoP9fXl5e6Nq1K86ePQu1Wo3q6mqUlpaajCkqKjLW9NVq9S1dODd/rq/ufycM9EQkLQbB8sUKFRUVOHfuHHx9fRESEgJnZ2dkZmYat+fn56OgoAAajQYAoNFocOLECRQXFxvHZGRkQKFQICgoyKxzs3RDRNJio/bKhIQEjBo1Cp06dUJhYSFee+01ODo6YuLEiVAqlZg6dSri4+Ph7e0NhUKBWbNmQaPRoF+/fgCAYcOGISgoCJMnT8aKFSug0+mwYMECxMTENPhbxE0M9ERETeDSpUuYOHEirl27hnbt2qF///44fPgw2rVrBwBYuXIlHBwcEBkZCb1ej/DwcKxZs8a4v6OjI9LT0zFz5kxoNBq4u7sjOjoaSUlJZs9FJgjiux94cacoe0+BbOjN4h/sPQWyoevXf7dq/79XzbB4X7fZKVad216Y0Tdj/V8cjcDhfdD2Xj/UVlXjYu4ZZCzfjGu/XTaOCZk4GMFjHobvAwGQe7piefA0VJX/bdzu1aEtBr70BAIeDoJHOy/8VfQnftp6EAfe24a6mjp7fCxqoISEFzF27HB07Xovrl+vQk5OLl59dTnOnPnNZFxoaG8sXvwy+vbtibq6Ovz00ymMGjUZVVW37++WNPHltnfFi7HNWOfQ7jj64ff4v7Gv4cNJy+Hg7IjJH70CZ9f/1OecXeU4m/UTDqz+ut5jtL3XDzKZDOmJG7AmbB52J32MPlFDMXTe07b6GGShAQNCkZLyIQYNGovHH58EJydnpKd/BDe3/7TmhYb2xtdfpyEzcz8GDBiN/v1HIyUlDQYrLxyKmo2eddOcsHTTgrh5e2Lev1Ow8ckl+P3ILybbOvcLxJTPFtyS0dfn4X9EoO+kMKwaENeU07UZqZRu2rb1xsWL/0ZY2JM4ePAIACAraysyM39AUtI7dp6d7Vhdunn7BYv3dUv4P6vObS92Ld1cvXoVGzZsQHZ2tvFOL7VajYcffhhTpkwxXrSgG1p5ugEArpdWWH0ca49BtqdQeAIA/vyzFADQrl0bPPRQb2ze/DX27v0KAQH++PXXc1i8+C0cOnTMjjNt5iT4him7lW6OHj2Krl27Ijk5GUqlEgMHDsTAgQOhVCqRnJyM7t2749gx/mW9SSaTYfhrk1FwNB/Fv16y+DjenVR4KHoYjn2ypxFnR01NJpPhrbdew6FDR3Hq1K8AgIAAfwDAq6/OwYYNn2LMmGjk5f2MHTs24d57O9txttTc2C2jnzVrFp588kmkpKRAJpOZbBMEATNmzMCsWbOMD/i5Hb1ef8tDhWqFOjjJHBt9zvY0cskU+HTtgA3jzW+tuslT1RqTPpyHUzty8OPmvY04O2pq7767BPff3xVDh443rnNwuJGnrV//CT76aAsA4Pjxk3j00UcQHf0UFi1aYZe5NnsSvH5ht4z++PHjiIuLuyXIAzeyl7i4OOTl5d31OPU9ZOiHMvOe7NbcjUyKRtehvZA68Q2U60osOoanjxembH4VF3PP4JtX1jfyDKkprVyZhJEjhyI8fCL++OM/D7O6fPnGHZOnT581GZ+ffxYdO7a36RxbEsFgsHhpqewW6NVqNY4cOXLb7UeOHLnlyW31SUxMRFlZmcnSX3l/Y07VrkYmRaN7eB+kTXwDpRevWHQMT1VrTPlsAQpPnMe2hPchwuvvorVyZRJGjw7H8OET8fvvF022/f77RRQW6tC16z0m67t0uQcFBZaX90TPTo9AsCe7lW4SEhIwffp05ObmYujQocagXlRUhMzMTKxbtw5vv/32XY8jl8tvuR1YLGWbiKVTEDz6YXw67Z+orqyCRzslAKCq/G/U6msAAB7tlPBo5wXvzjd+/3y6dUR1ZRXK/riK62WVxiBf9sdVfPfGJri3URiPX3GlzPYfihrs3XeX4umnR+PJJ6ehoqISKtWN5oSysnJjj/zKle9jwYI4nDhxGsePn8SkSePRrdu9eOYZy28KEj0JXoy1a3vlZ599hpUrVyI3Nxd1dTdu3nF0dERISAji4+Px1FNPWXRcsbRXLv79k3rXb5v7PvK+2A8AeHTOODwaF3nbMT3HD8TYd/5R//FF8vsk1vbK27URTps2Fx9//IXx54SEmfjHP55F69ZeOHHiNF59dZmou26sba+sTLL87737ovr/n2zumkUffU1NDa5evQoAaNu2LZydna06nlgCGDWMWAM91Y+B3nzN4hEIzs7O8PX1tfc0iEgKWvBFVUs1i0BPRGQzLfiiqqUY6IlIWiR4MZaBnoikhRk9EZG4teQbnyzFxxQTEYkcM3oikhaWboiIRI6BnohI5Nh1Q0QkcszoiYjETZBgoGfXDRGRyDGjJyJpkWBGz0BPRNIiwRumGOiJSFqY0RMRiRwDPRGRuDWDdy3ZHLtuiIhEjhk9EUkLSzdERCLHQE9EJG5SvDOWgZ6IpIWBnohI5KR3vxS7boiIxI4ZPRFJCmv0RERix0BPRCRyEqzRM9ATkaRIsXTDi7FEJC0GKxYrLF++HDKZDHPmzDGuq6qqQkxMDNq0aQMPDw9ERkaiqKjIZL+CggJERETAzc0NPj4+ePnll1FbW2vWuRnoiYia2NGjR/H+++/jwQcfNFkfFxeHb775Blu2bEFWVhYKCwsxbtw44/a6ujpERESguroahw4dQlpaGlJTU7Fo0SKzzs9AT0SSIhgEixdLVFRUICoqCuvWrUPr1q2N68vKyrB+/Xr885//xJAhQxASEoKNGzfi0KFDOHz4MADgu+++w6lTp/Dxxx+jZ8+eGDFiBJYsWYLVq1ejurq6wXNgoCciabGidKPX61FeXm6y6PX6O54uJiYGERERCAsLM1mfm5uLmpoak/Xdu3eHv78/srOzAQDZ2dkIDg6GSqUyjgkPD0d5eTlOnjzZ4I/MQE9EkiIYLF+0Wi2USqXJotVqb3uuzZs348cff6x3jE6ng4uLC7y8vEzWq1Qq6HQ645j/DvI3t9/c1lDsuiEiabHiompiYiLi4+NN1snl8nrHXrx4EbNnz0ZGRgZatWpl+UkbATN6IpIUazJ6uVwOhUJhstwu0Ofm5qK4uBi9e/eGk5MTnJyckJWVheTkZDg5OUGlUqG6uhqlpaUm+xUVFUGtVgMA1Gr1LV04N3++OaYhGOiJiJrA0KFDceLECeTl5RmXPn36ICoqyvhrZ2dnZGZmGvfJz89HQUEBNBoNAECj0eDEiRMoLi42jsnIyIBCoUBQUFCD58LSDRFJi43ujPX09MQDDzxgss7d3R1t2rQxrp86dSri4+Ph7e0NhUKBWbNmQaPRoF+/fgCAYcOGISgoCJMnT8aKFSug0+mwYMECxMTE3PabRH0Y6IlIUoRm9AiElStXwsHBAZGRkdDr9QgPD8eaNWuM2x0dHZGeno6ZM2dCo9HA3d0d0dHRSEpKMus8MkGEr0Rf3CnK3lMgG3qz+Ad7T4Fs6Pr1363av3joIIv39cnMsurc9sKMnogkpTll9LbCQE9E0iLI7D0Dm2PXDRGRyDGjJyJJYemGiEjkBIP0SjcM9EQkKczoiYhETpDgxVgGeiKSFClm9Oy6ISISOWb0RCQpvBhLRCRy4nvoy90x0BORpDCjJyISOQZ6IiKRk2Lphl03REQix4yeiCSFpRsiIpHjnbFmqK6uRnFxMQwG09vM/P39rZ4UEVFTkeKdsWYH+jNnzuD555/HoUOHTNYLggCZTIa6urpGmxwRUWMzMKO/uylTpsDJyQnp6enw9fWFTCa93zQiarlYummAvLw85Obmonv37k0xHyIiamRmB/qgoCBcvXq1KeZCRNTkpNh106A++vLycuPy5ptvYt68edi3bx+uXbtmsq28vLyp50tEZBVBsHxpqRqU0Xt5eZnU4gVBwNChQ03G8GIsEbUEUszoGxTo9+7d29TzICKyCXbd3MagQYOMvy4oKEDHjh1v6bYRBAEXL15s3NkREZHVzH7WTUBAAK5cuXLL+pKSEgQEBDTKpIiImoogyCxeWiqzu25u1uL/V0VFBVq1atUokyIiaiot+aKqpRoc6OPj4wEAMpkMCxcuhJubm3FbXV0dcnJy0LNnz0afIBFRY2KN/g7+/e9/A7iR0Z84cQIuLi7GbS4uLujRowcSEhIaf4ZERI2oJZdgLNXgQH+z8+a5557DqlWroFAommxSRERNhaWbBti4cWNTzIOIiJqI2YF+yJAhd9y+Z88eiydDRNTUWKNvgB49epj8XFNTg7y8PPz888+Ijo5utIlZY+nlffaeAtnQ9cID9p4CtSCs0TfAypUr612/ePFiVFRUWD0hIqKmJMWMvtFeDj5p0iRs2LChsQ5HRNQkBCuWlqrR3hmbnZ3NG6aIqNmTYkZvdqAfN26cyc+CIODy5cs4duwYFi5c2GgTIyKixmF2oFcqlSY/Ozg4oFu3bkhKSsKwYcMabWJERE2BF2Pvoq6uDs899xyCg4PRunXrppoTEVGTMdjoPGvXrsXatWtx4cIFAMD999+PRYsWYcSIEQCAqqoqzJ07F5s3b4Zer0d4eDjWrFkDlUplPEZBQQFmzpyJvXv3wsPDA9HR0dBqtXByMi9HN+tirKOjI4YNG4bS0lKzTkJE1FwIkFm8mKNDhw5Yvnw5cnNzcezYMQwZMgRjxozByZMnAQBxcXH45ptvsGXLFmRlZaGwsNCkNF5XV4eIiAhUV1fj0KFDSEtLQ2pqKhYtWmT2Z5YJgnk3BPfp0wdvvvnmLW+Yak6cXNrbewpkQ+yjlxbntvdYtf8+1ZMW7/to0Rarzu3t7Y233noL48ePR7t27bBp0yaMHz8eAPDLL78gMDAQ2dnZ6NevH3bu3InHH38chYWFxiw/JSUF8+fPx5UrV0yeN3Y3ZrdXLl26FAkJCUhPT8fly5f5zlgialEMkFm86PX6W2KeXq+/6znr6uqwefNmVFZWQqPRIDc3FzU1NQgLCzOO6d69O/z9/ZGdnQ3gRidjcHCwSSknPDwc5eXlxm8FDdXgQJ+UlITKykqMHDkSx48fx+jRo9GhQwe0bt0arVu3hpeXF+v2RCRqWq0WSqXSZNFqtbcdf+LECXh4eEAul2PGjBnYunUrgoKCoNPp4OLiAi8vL5PxKpUKOp0OAKDT6UyC/M3tN7eZo8EV/ddffx0zZszg+2OJqEUzt9b+3xITE43v5rhJLpffdny3bt2Ql5eHsrIyfPHFF4iOjkZWVpbF57dUgwP9zVL+f78/loiopbGm60Yul98xsP8vFxcXdOnSBQAQEhKCo0ePYtWqVXj66adRXV2N0tJSk6y+qKgIarUaAKBWq3HkyBGT4xUVFRm3mcOsGn19rxAkImpJbNV1Ux+DwQC9Xo+QkBA4OzsjMzPTuC0/Px8FBQXQaDQAAI1GgxMnTqC4uNg4JiMjAwqFAkFBQWad16xmzK5du9412JeUlJg1ASIiW7JVH31iYiJGjBgBf39//PXXX9i0aRP27duH3bt3Q6lUYurUqYiPj4e3tzcUCgVmzZoFjUaDfv36AQCGDRuGoKAgTJ48GStWrIBOp8OCBQsQExNj1rcKwMxA//rrr99yZywRUUtiq0BfXFyMZ599FpcvX4ZSqcSDDz6I3bt347HHHgNw40nADg4OiIyMNLlh6iZHR0ekp6dj5syZ0Gg0cHd3R3R0NJKSksyeS4P76B0cHKDT6eDj42P2SWyNffTSwj56abG2j36HaoLF+44s2mzVue2lwRk96/NEJAaNUWtvaczuuiEiaskM0ovzDQ/0BoOtKltERE3HwIyeiEjcpFibYKAnIkmRYm2i0d4ZS0REzRMzeiKSFIMEOwgZ6IlIUlijJyISOSnW6BnoiUhS2EdPRCRyUuyjZ9cNEZHIMaMnIknhxVgiIpFjjZ6ISOTYdUNEJHIs3RARiZwUSzfsuiEiEjlm9EQkKazRExGJHAM9EZHICRKs0TPQE5GkMKMnIhI5KQZ6dt0QEYkcM3oikhTeMEVEJHJSvGGKgZ6IJEWKNXoGeiKSFAZ6IiKRk2KNnl03REQix4yeiCSFF2OJiESONXoiIpGTYo2egZ6IJMUgwVDPQE9EkiLF0g27boiIRI4ZPRFJivQKNwz0RCQxUizdMNATkaRIsY+eNXoikhQDBIsXc2i1WvTt2xeenp7w8fHB2LFjkZ+fbzKmqqoKMTExaNOmDTw8PBAZGYmioiKTMQUFBYiIiICbmxt8fHzw8ssvo7a21qy5MNATkaQIVizmyMrKQkxMDA4fPoyMjAzU1NRg2LBhqKysNI6Ji4vDN998gy1btiArKwuFhYUYN26ccXtdXR0iIiJQXV2NQ4cOIS0tDampqVi0aJFZc5EJgiC6axNOLu3tPQWyoeuFB+w9BbIh57b3WLX/q52fsXjfNy5ssnjfK1euwMfHB1lZWRg4cCDKysrQrl07bNq0CePHjwcA/PLLLwgMDER2djb69euHnTt34vHHH0dhYSFUKhUAICUlBfPnz8eVK1fg4uLSoHMzoyciSTFYsej1epSXl5sser2+QectKysDAHh7ewMAcnNzUVNTg7CwMOOY7t27w9/fH9nZ2QCA7OxsBAcHG4M8AISHh6O8vBwnT55s8GdmoCciSbGmRq/VaqFUKk0WrVZ793MaDJgzZw4eeeQRPPDAAwAAnU4HFxcXeHl5mYxVqVTQ6XTGMf8d5G9uv7mtodh1Q0SSYk2tOjExEfHx8Sbr5HL5XfeLiYnBzz//jB9++MGKs1uOgZ6IJMWaPnq5XN6gwP7fYmNjkZ6ejv3796NDhw7G9Wq1GtXV1SgtLTXJ6ouKiqBWq41jjhw5YnK8m105N8c0BEs3RCQptmqvFAQBsbGx2Lp1K/bs2YOAgACT7SEhIXB2dkZmZqZxXX5+PgoKCqDRaAAAGo0GJ06cQHFxsXFMRkYGFAoFgoKCGjwXZvRERE0gJiYGmzZtwtdffw1PT09jTV2pVMLV1RVKpRJTp05FfHw8vL29oVAoMGvWLGg0GvTr1w8AMGzYMAQFBWHy5MlYsWIFdDodFixYgJiYGLO+WTDQE5Gk2KqffO3atQCARx991GT9xo0bMWXKFADAypUr4eDggMjISOj1eoSHh2PNmjXGsY6OjkhPT8fMmTOh0Wjg7u6O6OhoJCUlmTUX9tFTi8c+emmxto9+ducJFu+76sJmq85tL8zoiUhSBAk+v5KBnogkRYpPr2TXDRGRyDGjJyJJkeI7Y5nRtzAD+odi29ZUFFzIRW31Hxg9Otxk+6KF8fj5RBbK/jyDK0UnsXvnZjzUt5edZkvmKrpyFfNfX4FHRjyFkMFj8MTkmfj59K8AgJraWvxzzXo8MXkm+g4di8Gjo5C45G0UX7lmcowLBZcwa/7r6D/yaYQ+Ng6TZ87Fkdzj9vg4zZKtnl7ZnDDQtzDu7m746adTmDX71Xq3/3rmN8yevQA9ew/FoMFP4MLvF7Fzxya0bett45mSucrK/8LkGXPh7OSElHeW4OtP3kdC7AtQeHoAAKqq9DiVfw7/mDIRn294D+8uW4ALBZcQO/91k+PEzFuM2ro6rE9ejs83/AvdutyDmHmv4eq1Ent8rGbHVjdMNSdsr2zBaqv/wLjxz2P79t23HePp6YE/r+VjWPjT2LPXPs/ZaGpiaa9cuXYD/v3TKXy49u0G73PidD4mvjAHGV+mwVftgz9LyzAgYgLSVr+FkJ43Hp5VWfk3QodFYt27y6ARwbc7a9srp3V+0uJ9113YYtW57YUZvYg5Oztj2gtRKC0tw/GfGv5IU7KPvT8cxv3d70P8gjcwMGICxk+JwRfbd95xn4qKvyGTyeDp6Q4A8FIqEODfAdt3ZeLv61Wora3D51/vgHdrLwR162KLj9HsCVb811I160B/8eJFPP/88/aeRosTMTIMpSW/ovKv3zD7pWkYPmIirl37097Toru4VKjDZ9u+hX+H9nh/5VI8/UQEtCtT8PWOjHrH6/XVWLl2A0aGDYKH+41AL5PJsG7VMpz+9RxCHxuHkCGj8eHmrXj/n0ugVHja8uNQM9KsA31JSQnS0tLuOKa+FwGIsBpllr37DiKk7zAMGDgGu7/bh083paBduzb2nhbdhcEgILBrF8yZMQWBXbvgyTEjETl6OD7ftuOWsTW1tZi7cBkEQcDCl2ON6wVBwBvvrEGb1kqkrXkLn65bhSEDNYidtxhXrrJGD1j34pGWyq7tldu3b7/j9t9+++2ux9BqtXj9ddOLUTIHD8gcFVbNrSX7++/rOHfuAs6du4CcIz/i9Mkf8PxzE/HmivfsPTW6g3ZtvHFvZ3+Tdfd07ojv9x00WXczyBcWFWND8nJjNg8AObl5yDp0BId2fW5cH9QtFtlH/42vd36PFyY/1fQfpJlrySUYS9k10I8dOxYymeyOGbhMJrvjMep7EUDrNt0bZX5i4eAgg1zesHdLkv30ejAIFwoumaz7veAP+Kp9jD/fDPIFFwux4V/L4aU0TWiqqm681s5BZvpl3UEmg8HQknPSxiPF3wW7lm58fX3x1VdfwWAw1Lv8+OOPdz2GXC6HQqEwWe72j0NL5u7uhh497kePHvcDAAI6+6NHj/vRsaMf3NxcsXTJKwh9qDf8/dujd69grPvgHbRvr8YXX6bbeeZ0N5OfHoufTv6CD9I2o+BSIb79bi++2L4TE8c9DuBGkI9/9Q2c/OUMlr82DwaDAVevleDqtRLU1NQAAHo8EAiFpwf+39J38MuZ33Ch4BLefu//cOlyEQY+/JA9P16zYRAEi5eWyq7tlaNHj0bPnj1v+8jN48ePo1evXmZnImJurxw0UIPM77+4ZX3ah5/jxZhX8PFH7+Ghvr3Qtq03rl37E8dyj2PZslU4JuIbZsTSXgkA+w7mYFVKKn6/9Afa+6oRPeEJjB89AgDwx+UihI+fUu9+G/71Jh7q/SAA4OfTvyL5gzSc/OUMamtr0SWgE2Y89wwGaPra6mM0KWvbKyd1Gmfxvh///pVV57YXuwb6AwcOoLKyEsOHD693e2VlJY4dO4ZBgwaZdVwxB3q6lZgCPd0dA7357FqjHzBgwB23u7u7mx3kiYjupCXf4WopPtSMiCSFXTdERCInxa4bBnoikhSWboiIRE6KpZtm/QgEIiKyHjN6IpIU1uiJiEROig89ZKAnIknhxVgiIpFj6YaISOTYdUNERKLDjJ6IJIU1eiIikWPXDRGRyPFiLBGRyEnxYiwDPRFJihRr9Oy6ISISOWb0RCQpvBhLRCRyUizdMNATkaTwYiwRkcgZWLohIhI36YV5dt0QEYkeAz0RSYoBgsWLOfbv349Ro0bBz88PMpkM27ZtM9kuCAIWLVoEX19fuLq6IiwsDGfOnDEZU1JSgqioKCgUCnh5eWHq1KmoqKgw+zMz0BORpNgq0FdWVqJHjx5YvXp1vdtXrFiB5ORkpKSkICcnB+7u7ggPD0dVVZVxTFRUFE6ePImMjAykp6dj//79mD59utmfWSaIsKnUyaW9vadANnS98IC9p0A25Nz2Hqv27+f3qMX7Hi7cZ9F+MpkMW7duxdixYwHcyOb9/Pwwd+5cJCQkAADKysqgUqmQmpqKCRMm4PTp0wgKCsLRo0fRp08fAMCuXbswcuRIXLp0CX5+fg0+PzN6IpIUazJ6vV6P8vJyk0Wv15s9h/Pnz0On0yEsLMy4TqlUIjQ0FNnZ2QCA7OxseHl5GYM8AISFhcHBwQE5OTlmnY+BnogkRbDiP61WC6VSabJotVqz56DT6QAAKpXKZL1KpTJu0+l08PHxMdnu5OQEb29v45iGYnslEVEDJSYmIj4+3mSdXC6302wajoGeiCTFmsuScrm8UQK7Wq0GABQVFcHX19e4vqioCD179jSOKS4uNtmvtrYWJSUlxv0biqUbIpIUW3Xd3ElAQADUajUyMzON68rLy5GTkwONRgMA0Gg0KC0tRW5urnHMnj17YDAYEBoaatb5mNETkaTYqtGwoqICZ8+eNf58/vx55OXlwdvbG/7+/pgzZw6WLl2K++67DwEBAVi4cCH8/PyMnTmBgYEYPnw4pk2bhpSUFNTU1CA2NhYTJkwwq+MGYKAnIomx1dMrjx07hsGDBxt/vlnbj46ORmpqKubNm4fKykpMnz4dpaWl6N+/P3bt2oVWrVoZ9/nkk08QGxuLoUOHwsHBAZGRkUhOTjZ7LuyjpxaPffTSYm0f/YNqjcX7/qTLturc9sIaPRGRyLF0Q0SSwscUExGJHF88QkQkcszoiYhEjhk9EZHISTGjZ9cNEZHIMaMnIklh6YaISOSkWLphoCciSWFGT0QkcoJgsPcUbI6BnogkxVYPNWtO2HVDRCRyzOiJSFJE+MDeu2KgJyJJkWLphoGeiCSFGT0Rkcixj56ISOSk2EfPrhsiIpFjRk9EksIaPRGRyLHrhohI5JjRExGJHLtuiIhETooZPbtuiIhEjhk9EUkKL8YSEYmcFEs3DPREJCm8GEtEJHJ8BAIREYkOM3oikhSWboiIRI4XY4mIRE6KNXoGeiKSFGb0REQiJ8VAz64bIiKRY0ZPRJIivXwekAlS/B4jQnq9HlqtFomJiZDL5faeDjUx/nmTORjoRaK8vBxKpRJlZWVQKBT2ng41Mf55kzlYoyciEjkGeiIikWOgJyISOQZ6kZDL5Xjttdd4YU4i+OdN5uDFWCIikWNGT0Qkcgz0REQix0BPRCRyDPRERCLHQC8Sq1evRufOndGqVSuEhobiyJEj9p4SNYH9+/dj1KhR8PPzg0wmw7Zt2+w9JWoBGOhF4LPPPkN8fDxee+01/Pjjj+jRowfCw8NRXFxs76lRI6usrESPHj2wevVqe0+FWhC2V4pAaGgo+vbti/feew8AYDAY0LFjR8yaNQuvvPKKnWdHTUUmk2Hr1q0YO3asvadCzRwz+hauuroaubm5CAsLM65zcHBAWFgYsrOz7TgzImouGOhbuKtXr6Kurg4qlcpkvUqlgk6ns9OsiKg5YaAnIhI5BvoWrm3btnB0dERRUZHJ+qKiIqjVajvNioiaEwb6Fs7FxQUhISHIzMw0rjMYDMjMzIRGo7HjzIioueA7Y0UgPj4e0dHR6NOnDx566CG8++67qKysxHPPPWfvqVEjq6iowNmzZ40/nz9/Hnl5efD29oa/v78dZ0bNGdsrReK9997DW2+9BZ1Oh549eyI5ORmhoaH2nhY1sn379mHw4MG3rI+OjkZqaqrtJ0QtAgM9EZHIsUZPRCRyDPRERCLHQE9EJHIM9EREIsdAT0Qkcgz0REQix0BPRCRyDPTUokyZMsXk+euPPvoo5syZY/N57Nu3DzKZDKWlpTY/N5G5GOipUUyZMgUymQwymQwuLi7o0qULkpKSUFtb26Tn/eqrr7BkyZIGjWVwJqnis26o0QwfPhwbN26EXq/Hjh07EBMTA2dnZyQmJpqMq66uhouLS6Oc09vbu1GOQyRmzOip0cjlcqjVanTq1AkzZ85EWFgYtm/fbiy3vPHGG/Dz80O3bt0AABcvXsRTTz0FLy8veHt7Y8yYMbhw4YLxeHV1dYiPj4eXlxfatGmDefPm4X+f2PG/pRu9Xo/58+ejY8eOkMvl6NKlC9avX48LFy4YnxHTunVryGQyTJkyBcCNp31qtVoEBATA1dUVPXr0wBdffGFynh07dqBr165wdXXF4MGDTeZJ1Nwx0FOTcXV1RXV1NQAgMzMT+fn5yMjIQHp6OmpqahAeHg5PT08cOHAABw8ehIeHB4YPH27c55133kFqaio2bNiAH374ASUlJdi6desdz/nss8/i008/RXJyMk6fPo33338fHh4e6NixI7788ksAQH5+Pi5fvoxVq1YBALRaLT788EOkpKTg5MmTiIuLw6RJk5CVlQXgxj9I48aNw6hRo5CXl4cXXniB7+KllkUgagTR0dHCmDFjBEEQBIPBIGRkZAhyuVxISEgQoqOjBZVKJej1euP4jz76SOjWrZtgMBiM6/R6veDq6irs3r1bEARB8PX1FVasWGHcXlNTI3To0MF4HkEQhEGDBgmzZ88WBEEQ8vPzBQBCRkZGvXPcu3evAED4888/jeuqqqoENzc34dChQyZjp06dKkycOFEQBEFITEwUgoKCTLbPnz//lmMRNVes0VOjSU9Ph4eHB2pqamAwGPDMM89g8eLFiImJQXBwsEld/vjx4zh79iw8PT1NjlFVVYVz586hrKwMly9fNnnUspOTE/r06XNL+eamvLw8ODo6YtCgQQ2e89mzZ/H333/jscceM1lfXV2NXr16AQBOnz59yyOf+VIXakkY6KnRDB48GGvXroWLiwv8/Pzg5PSfv17u7u4mYysqKhASEoJPPvnkluO0a9fOovO7urqavU9FRQUA4Ntvv0X79u1NtsnlcovmQdTcMNBTo3F3d0eXLl0aNLZ379747LPP4OPjA4VCUe8YX19f5OTkYODAgQCA2tpa5Obmonfv3vWODw4OhsFgQFZWFsLCwm7ZfvMbRV1dnXFdUFAQ5HI5CgoKbvtNIDAwENu3bzdZd/jw4bt/SKJmghdjyS6ioqLQtm1bjBkzBgcOHMD58+exb98+vPTSS7h06RIAYPbs2Vi+fDm2bduGX375BS+++OIde+A7d+6M6OhoPP/889i2bZvxmJ9//jkAoFOnTpDJZEhPT8eVK1dQUVEBT09PJCQkIC4uDmlpaTh37hx+/PFH/Otf/0JaWhoAYMaMGThz5gxefvll5OfnY9OmTXybE7UoDPRkF25ubti/fz/8/f0xbtw4BAYGYurUqaiqqjJm+HPnzsXkyZMRHR0NjUYDT09PPPHEE3c87tq1azF+/Hi8+OKL6N69O6ZNm4bKykoAQPv27fH666/jlVdegUqlQmxsLABgyZIlWLhwIbRaLQIDAzF8+HB8++23CAgIAAD4+/vjyy+/xLZt29CjRw+kpKRg2bJlTfi7Q9S4+CpBIiKRY0ZPRCRyDPRERCLHQE9EJHIM9EREIsdAT0Qkcgz0REQix0BPRCRyDPRERCLHQE9EJHIM9EREIsdAT0Qkcgz0REQi9/8BYhBVgaBU2NoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CNN()\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate=True)\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      ".......... Epoch [1/10], ( 28/ 28), Train Loss: 0.7667, Val Loss: 0.7641, Accuracy: 25.17%\n",
      ".......... Epoch [2/10], ( 28/ 28), Train Loss: 0.7684, Val Loss: 0.7647, Accuracy: 24.26%\n",
      ".......... Epoch [3/10], ( 28/ 28), Train Loss: 0.7671, Val Loss: 0.7675, Accuracy: 25.85%\n",
      ".......... Epoch [4/10], ( 28/ 28), Train Loss: 0.7676, Val Loss: 0.7654, Accuracy: 23.58%\n",
      ".......... Epoch [5/10], ( 28/ 28), Train Loss: 0.7656, Val Loss: 0.7668, Accuracy: 24.15%\n",
      ".......... Epoch [6/10], ( 28/ 28), Train Loss: 0.7673, Val Loss: 0.7653, Accuracy: 24.72%\n",
      ".......... Epoch [7/10], ( 28/ 28), Train Loss: 0.7666, Val Loss: 0.7674, Accuracy: 23.80%\n",
      ".......... Epoch [8/10], ( 28/ 28), Train Loss: 0.7666, Val Loss: 0.7694, Accuracy: 24.37%\n",
      ".......... Epoch [9/10], ( 28/ 28), Train Loss: 0.7675, Val Loss: 0.7620, Accuracy: 24.94%\n",
      ".......... Epoch [10/10], ( 28/ 28), Train Loss: 0.7667, Val Loss: 0.7660, Accuracy: 24.26%\n",
      "\n",
      "Accuracy  : 26.39%\n",
      "Precision : 34.68%\n",
      "Recall    : 26.39%\n",
      "F1 Score  : 15.40%\n",
      "AUC Score : 29.52%\n",
      "GoogLeNet\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not GoogLeNetOutputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [resnet18, googlenet, densenet121]:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_seperate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     test_model(model, test_loader, display_cm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[250], line 35\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(nn, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate)\u001b[0m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \n\u001b[0;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m nn(inputs)\n\u001b[1;32m---> 35\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not GoogLeNetOutputs"
     ]
    }
   ],
   "source": [
    "# Denna använder resnet18, googlenet, och densenet121\n",
    "# https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0256630\n",
    "\n",
    "resnet18    = models.resnet18()\n",
    "googlenet   = models.googlenet()\n",
    "densenet121 = models.densenet121()\n",
    "\n",
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.device    = _device\n",
    "googlenet.device   = _device\n",
    "densenet121.device = _device\n",
    "\n",
    "resnet18.fc            = torch.nn.Linear(resnet18.fc.in_features, 2)\n",
    "googlenet.fc           = torch.nn.Linear(googlenet.fc.in_features, 2)\n",
    "densenet121.classifier = torch.nn.Linear(densenet121.classifier.in_features, 2)\n",
    "\n",
    "#cnn = CNN()\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for model in [resnet18, googlenet, densenet121]:\n",
    "    print(model.__class__.__name__)\n",
    "    train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate=True)\n",
    "    test_model(model, test_loader, display_cm = False)\n",
    "\n",
    "print(\"Ensemble test:\")\n",
    "test_ensemble([resnet18, googlenet, densenet121], test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
