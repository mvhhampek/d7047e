{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste från lab0\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        print(f\"Device: {str(self.device).upper()}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm = True):\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "    auc = roc_auc_score(all_targets, [p[1] for p in all_probs])\n",
    "        \n",
    "    print(f\"\\rAccuracy  : {accuracy*100:.2f}%\")\n",
    "    print(f\"Precision : {precision*100:.2f}%\")\n",
    "    print(f\"Recall    : {recall*100:.2f}%\")\n",
    "    print(f\"F1 Score  : {f1*100:.2f}%\")\n",
    "    print(f\"AUC Score : {auc*100:.2f}%\")\n",
    "    if display_cm:\n",
    "        cm = confusion_matrix(all_targets, all_predictions)\n",
    "        plt.figure(figsize=(4,4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Truth')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(nn, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate = False, patience=5) -> None:\n",
    "    \"\"\"\n",
    "    Train and validate a neural network model with early stopping.\n",
    "\n",
    "    Parameters:\n",
    "    - nn : torch.nn.Module\n",
    "        The neural network model to train and validate.\n",
    "    - train_loader : DataLoader\n",
    "        The DataLoader containing the training dataset.\n",
    "    - val_loader : DataLoader\n",
    "        The DataLoader containing the validation dataset.\n",
    "    - criterion : torch.nn.Module\n",
    "        The loss function to use.\n",
    "    - optimizer : torch.optim.Optimizer\n",
    "        The optimizer to use.\n",
    "    - num_epochs : int\n",
    "        The number of epochs to train the model.\n",
    "    - patience : int\n",
    "        The number of epochs to wait for improvement in validation loss before stopping.\n",
    "    \"\"\"\n",
    "\n",
    "    nn.to(nn.device)\n",
    "\n",
    "    n = int(len(str(abs(num_epochs))))\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        nn.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        ind = 0\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = nn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            print(f\"\\rTraining.. Epoch [{epoch+1:>n}/{num_epochs:>n}], ({ind+1:>3}/{len(train_loader)})\", end=\"\")\n",
    "            ind += 1\n",
    "\n",
    "        nn.eval()\n",
    "        total_val_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ind = 0\n",
    "            for batch in val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "\n",
    "                outputs = nn(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_predictions += labels.size(0)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                print(f\"\\rValidating Epoch [{epoch+1:>n}/{num_epochs:>n}], ({ind+1:>3}/{len(val_loader):>3})\", end=\"\")\n",
    "                ind += 1\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "\n",
    "        print(f'\\r.......... Epoch [{epoch+1:>n}/{num_epochs:>n}], ({len(val_loader):>3}/{len(val_loader):>3}), Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy*100:.2f}%', end=\"\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\" Early stopping: {epochs_no_improve}/{patience}\", end=\"\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"\\nNo improvement in {epochs_no_improve} epochs, stopping early.\")\n",
    "                break\n",
    "        # Early stopping \n",
    "        if print_seperate:\n",
    "            print()\n",
    "    print()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def test_model(nn, test_loader, display_cm = True) -> None:\n",
    "    \"\"\"\n",
    "    Test a neural network model on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model : torch.nn.Module\n",
    "        The trained neural network model to test.\n",
    "    - test_loader : DataLoader\n",
    "        The DataLoader for the test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(\"\\rTesting...\", end = \"\")\n",
    "    nn.to(nn.device)\n",
    "    nn.eval()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(nn.device), labels.to(nn.device)\n",
    "            outputs = nn(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # För F1, Rec, Pre, AUC:\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Compute evalulation metrics\n",
    "    evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_prediction(models: list[torch.nn.Module], inputs: torch.Tensor):\n",
    "    device = models[0].device\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "    # Averagar modellernas output, vi borde testa typ weighted averaging och eller boosting\n",
    "    with torch.no_grad():\n",
    "        outputs = sum(model(inputs) for model in models) / len(models)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "def test_ensemble(models: list[torch.nn.Module], test_loader: DataLoader, display_cm = True):\n",
    "    device = models[0].device\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = ensemble_prediction(models, inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            # För F1, Rec, Pre, AUC:\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    evaluation_metrics(correct_predictions, total_predictions, all_targets, all_predictions, all_probs, display_cm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_directory = \"C:/Users/hampu/Documents/kurser/år3/d7047e/images\"\n",
    "local_directory = \"C:/Users/hampek/Documents/school/d7047e/images\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4815], std=[0.2221]) # <-- beräknat med compute_mean_std() mean=[0.4815], std=[0.2221]\n",
    "])\n",
    "\n",
    "full_dataset = ImageFolder(root=local_directory, transform=transform)\n",
    "\n",
    "# 70/15/15 split\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True,  num_workers = num_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size = batch_size, shuffle=False, num_workers = num_workers)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size = batch_size, shuffle=False, num_workers = num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(): \n",
    "    # tar fram mean och std för hela datasettet, till transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    data = ImageFolder(root=local_directory, transform=transform)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=1, shuffle=False)\n",
    "\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    total_samples = 0\n",
    "    for data, _ in loader:\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        total_samples += batch_samples\n",
    "\n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "\n",
    "    print(\"Mean:\", mean)\n",
    "    print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: CPU\n",
      ".......... Epoch [1/100], ( 28/ 28), Train Loss: 0.4527, Val Loss: 0.1581, Accuracy: 94.42%\n",
      ".......... Epoch [2/100], ( 28/ 28), Train Loss: 0.1526, Val Loss: 0.1395, Accuracy: 95.33%\n",
      ".......... Epoch [3/100], ( 28/ 28), Train Loss: 0.1186, Val Loss: 0.1397, Accuracy: 94.65% Early stopping: 1/5\n",
      ".......... Epoch [4/100], ( 28/ 28), Train Loss: 0.1045, Val Loss: 0.1362, Accuracy: 95.10%\n",
      ".......... Epoch [5/100], ( 28/ 28), Train Loss: 0.0862, Val Loss: 0.1766, Accuracy: 93.74% Early stopping: 1/5\n",
      ".......... Epoch [6/100], ( 28/ 28), Train Loss: 0.0584, Val Loss: 0.1542, Accuracy: 94.87% Early stopping: 2/5\n",
      ".......... Epoch [7/100], ( 28/ 28), Train Loss: 0.0550, Val Loss: 0.1641, Accuracy: 94.53% Early stopping: 3/5\n",
      ".......... Epoch [8/100], ( 28/ 28), Train Loss: 0.0372, Val Loss: 0.1646, Accuracy: 94.65% Early stopping: 4/5\n",
      ".......... Epoch [9/100], ( 28/ 28), Train Loss: 0.0416, Val Loss: 0.1799, Accuracy: 94.87% Early stopping: 5/5\n",
      "No improvement in 5 epochs, stopping early.\n",
      "\n",
      "Accuracy  : 93.29%\n",
      "Precision : 93.39%\n",
      "Recall    : 93.29%\n",
      "F1 Score  : 93.13%\n",
      "AUC Score : 97.76%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CNN()\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate=True)\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\googlenet.py:47: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      ".......... Epoch [1/10], ( 28/ 28), Train Loss: 0.7667, Val Loss: 0.7641, Accuracy: 25.17%\n",
      ".......... Epoch [2/10], ( 28/ 28), Train Loss: 0.7684, Val Loss: 0.7647, Accuracy: 24.26%\n",
      ".......... Epoch [3/10], ( 28/ 28), Train Loss: 0.7671, Val Loss: 0.7675, Accuracy: 25.85%\n",
      ".......... Epoch [4/10], ( 28/ 28), Train Loss: 0.7676, Val Loss: 0.7654, Accuracy: 23.58%\n",
      ".......... Epoch [5/10], ( 28/ 28), Train Loss: 0.7656, Val Loss: 0.7668, Accuracy: 24.15%\n",
      ".......... Epoch [6/10], ( 28/ 28), Train Loss: 0.7673, Val Loss: 0.7653, Accuracy: 24.72%\n",
      ".......... Epoch [7/10], ( 28/ 28), Train Loss: 0.7666, Val Loss: 0.7674, Accuracy: 23.80%\n",
      ".......... Epoch [8/10], ( 28/ 28), Train Loss: 0.7666, Val Loss: 0.7694, Accuracy: 24.37%\n",
      ".......... Epoch [9/10], ( 28/ 28), Train Loss: 0.7675, Val Loss: 0.7620, Accuracy: 24.94%\n",
      ".......... Epoch [10/10], ( 28/ 28), Train Loss: 0.7667, Val Loss: 0.7660, Accuracy: 24.26%\n",
      "\n",
      "Accuracy  : 26.39%\n",
      "Precision : 34.68%\n",
      "Recall    : 26.39%\n",
      "F1 Score  : 15.40%\n",
      "AUC Score : 29.52%\n",
      "GoogLeNet\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not GoogLeNetOutputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [resnet18, googlenet, densenet121]:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_seperate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     test_model(model, test_loader, display_cm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[250], line 35\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(nn, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate)\u001b[0m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \n\u001b[0;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m nn(inputs)\n\u001b[1;32m---> 35\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hampek\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not GoogLeNetOutputs"
     ]
    }
   ],
   "source": [
    "# Denna använder resnet18, googlenet, och densenet121\n",
    "# https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0256630\n",
    "\n",
    "resnet18    = models.resnet18()\n",
    "googlenet   = models.googlenet()\n",
    "densenet121 = models.densenet121()\n",
    "\n",
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.device    = _device\n",
    "googlenet.device   = _device\n",
    "densenet121.device = _device\n",
    "\n",
    "resnet18.fc            = torch.nn.Linear(resnet18.fc.in_features, 2)\n",
    "googlenet.fc           = torch.nn.Linear(googlenet.fc.in_features, 2)\n",
    "densenet121.classifier = torch.nn.Linear(densenet121.classifier.in_features, 2)\n",
    "\n",
    "#cnn = CNN()\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for model in [resnet18, googlenet, densenet121]:\n",
    "    print(model.__class__.__name__)\n",
    "    train_and_validate(model, train_loader, val_loader, criterion, optimizer, num_epochs, print_seperate=True)\n",
    "    test_model(model, test_loader, display_cm = False)\n",
    "\n",
    "print(\"Ensemble test:\")\n",
    "test_ensemble([resnet18, googlenet, densenet121], test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
